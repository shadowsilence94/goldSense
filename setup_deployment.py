#!/usr/bin/env python3
"""
Setup script to prepare the project for deployment
Copies necessary files to correct locations
"""

import os
import shutil
from pathlib import Path

def setup_deployment():
    """Prepare project for deployment"""
    
    print("üöÄ Setting up Gold Price Prediction for deployment...\n")
    
    # Get project root
    project_root = Path(__file__).parent
    
    # Create necessary directories
    models_dir = project_root / 'models'
    webapp_models_dir = project_root / 'webapp' / 'models'
    results_dir = project_root / 'results'
    webapp_static_dir = project_root / 'webapp' / 'static'
    
    for dir_path in [models_dir, webapp_models_dir, results_dir, webapp_static_dir]:
        dir_path.mkdir(parents=True, exist_ok=True)
        print(f"‚úÖ Directory: {dir_path.name}")
    
    # Copy visualizations to results if they don't exist there
    print("\nüìä Setting up visualizations...")
    viz_files = [
        'DailyClosePrice.png',
        'model comparison.png',
        'CorrelationHeatmap.png',
        'enhanced_correlation_heatmap.png',
        'enhanced_time_series_all.png',
        'feature_importance_enhanced.png',
        'prediction_vs_actual.png',
        'lstm_training_history.png'
    ]
    
    copied_viz = 0
    for viz_file in viz_files:
        source = project_root / viz_file
        dest = results_dir / viz_file
        
        if source.exists() and not dest.exists():
            shutil.copy2(source, dest)
            print(f"  üìà Copied: {viz_file}")
            copied_viz += 1
        elif dest.exists():
            print(f"  ‚úì Exists: {viz_file}")
        else:
            print(f"  ‚ö†Ô∏è  Missing: {viz_file} (will be generated by notebook)")
    
    if copied_viz > 0:
        print(f"\n‚úÖ Copied {copied_viz} visualizations to results/")
    
    # Check for model files
    print("\nü§ñ Checking for trained models...")
    model_files = list(models_dir.glob('*.pkl')) + list(models_dir.glob('*.h5'))
    
    if len(model_files) == 0:
        print("  ‚ö†Ô∏è  No trained models found in models/ directory")
        print("  üìù You need to run the training notebook to generate models:")
        print("     - GoldSense_Train_Local.ipynb (for local training)")
        print("     - GoldSense_Train_Combined_colab.ipynb (for Colab)")
        print("\n  üí° The notebook should save these files:")
        print("     - models/best_model.pkl or best_model.h5")
        print("     - models/scaler_X.pkl")
        print("     - models/scaler_y.pkl")
        print("     - models/feature_names.pkl")
        print("     - models/metadata.pkl")
    else:
        print(f"  ‚úÖ Found {len(model_files)} model files:")
        for model_file in model_files:
            size_mb = model_file.stat().st_size / (1024 * 1024)
            print(f"     - {model_file.name} ({size_mb:.2f} MB)")
    
    # Create README for models directory
    models_readme = models_dir / 'README.md'
    if not models_readme.exists():
        models_readme.write_text("""# Models Directory

This directory contains trained machine learning models for gold price prediction.

## Required Files

The webapp needs these files to function:
- `best_model.pkl` or `best_model.h5` - Trained model
- `scaler_X.pkl` - Feature scaler
- `scaler_y.pkl` - Target scaler
- `feature_names.pkl` - List of feature names
- `metadata.pkl` - Model metadata and metrics

## How to Generate Models

Run one of these notebooks to train models:
1. **GoldSense_Train_Local.ipynb** - For local training
2. **GoldSense_Train_Combined_colab.ipynb** - For Google Colab

The notebooks will automatically save trained models to this directory.

## Git LFS for Large Models

If models exceed 100MB, use Git LFS:
```bash
git lfs track "models/*.h5"
git lfs track "models/*.pkl"
git add .gitattributes
```
""")
        print(f"\n  üìÑ Created: models/README.md")
    
    # Create .gitattributes for Git LFS if needed
    gitattributes = project_root / '.gitattributes'
    if not gitattributes.exists():
        gitattributes.write_text("""# Git LFS for large model files
models/*.h5 filter=lfs diff=lfs merge=lfs -text
models/*.pkl filter=lfs diff=lfs merge=lfs -text
""")
        print(f"  üìÑ Created: .gitattributes (for Git LFS)")
    
    print("\n‚úÖ Deployment setup complete!")
    print("\nüìã Next steps:")
    print("   1. Train models using the notebook if not already done")
    print("   2. Test webapp locally: cd webapp && python app.py")
    print("   3. Commit models and visualizations to git")
    print("   4. Push to GitHub")
    print("   5. Deploy to AWS (see AWS_DEPLOYMENT_GUIDE.md)")
    
    return True

if __name__ == '__main__':
    setup_deployment()
